% http://latex.silmaril.ie/formattinginformation/writing.html
% https://ml-cheatsheet.readthedocs.io/en/latest/index.html

\documentclass[a4paper]{article}
\usepackage[a4paper,left=4.8em,top=4.8em,bottom=4.8em,right=4.8em]{geometry}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{float}
\usepackage{subcaption}
\usepackage[bottom]{pkgs/footmisc}
\usepackage{amsmath}

\usepackage[bookmarks,pdfusetitle]{hyperref}
\hypersetup{colorlinks=true,linkcolor=.,filecolor=purple,urlcolor=teal}

\usepackage{pkgs/enumitem}
\setlist{nosep}

\setcounter{secnumdepth}{3}
\setlength{\parindent}{0em}
\setlength{\parskip}{0.4em}

\begin{document}

\title{Multilayer perceptron}
\author{alek3y}
\date{}
\maketitle

\section{Introduction}

The \textbf{multilayer perceptron} is one of the most common type of neural networks. Specifically, a feedfoward artificial neural network (\textbf{FFNN}).

The fundamental components of a neural network are:

\begin{itemize}
\item
\textbf{Weights}: They're used to determine the importance of a single neuron with respect to the next neuron.
\item
\textbf{Neurons}: They're like cells of the network that have the task of computing the \href{https://qr.ae/pGEzdE}{weighted sum} of the neurons on the previous layer (called \textit{inputs}) through the use of \textit{weights}.
\item
\textbf{Biases}: They help to determine how easy it is for the network to consider their associated neuron active\footnote{\href{https://stackoverflow.com/a/54651771}{What is the role of the bias in neural networks?}}, i.e. with a big bias it's easy for the neuron to be active, but with a negative bias it's more difficult.
\end{itemize}

All neurons of this type of perceptron are connected between each layer.

\begin{figure}[H]
\centering
\includegraphics[width=14em]{assets/ann-layers.pdf}
\caption{Neural network with one hidden layer}
\label{fig:ann-layers}
\end{figure}

\subsection{Layers}

The neurons of the network are grouped into multiple layers depending on their role.

Being the first layer, the \textbf{input layer} is the only one that doesn't alter its input, which would be the external data. \\
Consider a \textit{25 by 25 pixels} image of cat, a cute one.
For the network to recognize it you might want to feed it each pixel, which would make the input layer \textit{625 neurons} in size.

After its computations, the network processes the data on the \textbf{output layer}, which produces the ultimate result. \\
Continuing with the previous example, the output layer could consist of \textit{2 neurons}. One that classifies the image as \textit{"Dog"} and the other as \textit{"Cat"}.

Between the previously mentioned layers, there are one or more \textbf{hidden layers}.
Broadly speaking, their task is to recognize patterns by building on top of the previous ones to get more and more sophisticated features. \\
To actually classify the cat picture, the network might learn to recognize edges, then the shape of the eyes and mouth, and lastly their positions.

\newpage

\subsection{Linearity}

\subsubsection{Linear perceptron}

Linear perceptrons classifiers, also called \textbf{single-layer perceptrons}, are the \textit{simplest} feedfoward neural network available, as they have no hidden layers.
They're limited to to \textit{linearly separable} datasets, which are a set of points that \textbf{can} be separated by a linear function for classification.

\begin{figure}[H]
\centering
\includegraphics[width=18em]{assets/dataset-linear.png}
\caption{Dataset separated by the linear function $f(x)$}
\label{fig:dataset-linear}
\end{figure}

As it can be seen on \autoref{fig:dataset-linear}, the straight line $f(x)$ is able to separate the set of \textit{blue} and \textit{orange} points correctly, which allows a linear perceptron to classify them.

Ideally, the network just has to learn what the values of the slope $m$ and the intercept $q$ are for the line $f(x) = mx + q$.

\subsubsection{Non-linear perceptron}

For a more complex classification, \textbf{multilayer perceptrons} are necessary.

As the name implies, for a perceptron to be \textit{multilayer} it has to have at least one hidden layer.
Furthermore, a non-linear \textit{activation function} \textbf{must} be used for the network the be non-linear itself.

% TODO: Mention forward propagation on the weighted sum
An \textbf{activation function} is a function that changes the weighted sum of a neuron to be non-linear.
Two honorable mentions, as show in \autoref{fig:activation-functions}, are:

\begin{itemize}
\item
\textbf{Sigmoid}, which is expressed as $s(x)=\frac{1}{1 + e^{-x}}$, and it maps its argument to the range $\left[0, 1\right]$.
\item
\textbf{ReLU}, expressed as $r(x)=max(0, x)$, it ignores everything but the positive part of its argument.
Although it improves the performance, some neurons might ultimately become inactive for all inputs, effectively dying.
\end{itemize}

\begin{figure}[H]
\centering
\includegraphics[width=14em]{assets/activation-functions.pdf}
\caption{$r(x)$ as \textit{ReLU}, and $s(x)$ as \textit{sigmoid}}
\label{fig:activation-functions}
\end{figure}

\newpage

This type of network is considered to be capable of approximating any continuous function\footnote{\href{https://www.youtube.com/watch?v=Ijqkc7OLenI}{The Universal Approximation Theorem for neural networks}}, as proven by the \href{https://en.wikipedia.org/wiki/Universal_approximation_theorem}{universal approximation theorem}.

Because of that, the neural network can learn to approximate the required non-linear function to separate a set of points in a complex dataset, like shown in \autoref{fig:dataset-nonlinear}.

\begin{figure}[H]
\centering
\includegraphics[width=18em]{assets/dataset-nonlinear.png}
\caption{Complex dataset separated by $g(x)$}
\label{fig:dataset-nonlinear}
\end{figure}

\subsection{Learning}

For the neural network to learn and improve, it has to know how good its output was.
This result is given by the \textbf{loss function}, which computes the \textbf{cost} of the entire network given their parameters (\textit{weights} and \textit{biases}).

Lowering the cost as much as possible is the goal of the network, and to do that every single parameter is going to be slightly altered.
This alteration is found with the \textit{gradient} of the loss function.

\begin{figure}[H]
\centering
\begin{subfigure}{14em}
\includegraphics[width=\textwidth]{assets/descent-local.pdf}
\caption{Local minima\footnotemark}
\end{subfigure}
\hspace{1em}
\begin{subfigure}{14em}
\includegraphics[width=\textwidth]{assets/descent-global.pdf}
\caption{Global minima}
\label{fig:descent-global}
\end{subfigure}
\caption{Gradient descent for $A$}
\label{fig:descent}
\end{figure}

\footnotetext{\url{https://www.desmos.com/calculator/jcksoztqbl}}

Let's take $A_x$ as one parameter to be altered on the loss function $C(x)$, as shown in both situations in \autoref{fig:descent}.

Just using the direction of the \textit{gradient} for $A_x$ would lead the point towards the fastest increase in the function, which is the opposite of that intended.
Getting the direction of fastest decrease is simply a matter of using the \textbf{negative} of said \textit{gradient} which, in this case, would push $A$ towards $M$ moving it in $B$'s place.

This is referred to as \textbf{gradient descent} and is expressed as $-\eta\nabla C(x)$.

\subsubsection{Learning rate}

The size of each step towards a minima $M$ is scaled down or up by the constant $\eta$, called \textbf{learning rate}, inside the \textit{gradient descent} formula.
Choosing the right constant is very significant for the learning efficiency of the network.

Using a constant that is too small might make the network terribly slow at learning. \\
However, using one that is too large might overshoot the targeted minima when stepping, e.g. $A$ on \autoref{fig:descent-global} might end up falling on $M_1$ instead of $M_2$.

\subsubsection{Minima}

Learning is a matter of minimizing the overall cost of the network, by changing the parameters so that it will reach the nearest concavity called \textbf{local minima}.

The loss function is very likely to have plenty of minimas though, and the most effective is called \textbf{global minima}. \\
This is why it is not guaranteed for a trained network to have the most performant configuration.
It all depends on the initial values assigned to each parameter.

\subsubsection{Dimensions}

Plotting the loss function as if it had just one parameter like shown in \autoref{fig:descent} isn't really realistic.
In reality, you might have multiple thousands of those \textit{weights} and \textit{biases}.

So, if the \textit{x-axis} is the value of that one parameter, adding more will result in increasing the dimensional space of the graph.

\begin{figure}[H]
\centering
\includegraphics[width=18em]{assets/descent-3d.png}
\caption{Gradient descent for $E$ in a three-dimensional space}
\label{fig:dimensions}
\end{figure}

As proof, take the two weights $w_1$ and $w_2$ as shown in \autoref{fig:dimensions}. \\
The plotted graph shows the cost for all of the possible combinations of the two values.
Therefore, the aim of the \textit{gradient descent} is to make slight alterations to those two values so that it will bring $E$ closer to nearest minima.

\begin{equation}
-\eta\nabla C\left(
\begin{bmatrix}
w_1 \\
w_2 \\
\vdots \\
w_n
\end{bmatrix}
\right) =
\begin{bmatrix}
\Delta w_1 \\
\Delta w_2 \\
\vdots \\
\Delta w_n
\end{bmatrix}
\label{eq:dimensions-gradient}
\end{equation}

Although it might be difficult to visualize, \hyperref[eq:dimensions-gradient]{the previous equation} shows how the result is the alteration $\Delta w_i$ that will then be added to its corresponding parameter $w_i$, which will move the point on the $n$-dimensional space.

\end{document}
